---
title: "KMeansStability-Vignette"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{KMeansStability-Vignette}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
library(KMeansStability)
```

The KmeansStability Package implements a set of distance metrics used to select $K$ in $K$-means clustering for a future small simulation study. Unlike traditional optimization problems, the objective of $K$-means is monotonically decreasing in $K$, requiring the analyst to appear to other criterion to optimize $K$. In the stability school of thought, the optimize selection of $K$ induces a clustering which is mostly likely to reappear on another sampling of the population. The stability workflow operates in steps. First, one resamples from a given dataset to emulate collecting multiple samples from the population. For each pair of samples, one clusters them over a range of values for $K$. Lastly, for each value of $K$, a distance metric is applied to each pair of clusters, and the average of the distance metric is computed. The value of $K$ which attains the smallest average distance is declared the most stable.

The KMeansStablity implements two cannon distance metrics, Mininum Matching distance and Comembership distance, along with three novel distance metrics. For two clusterings $C_1$ and $C_2$ of a dataset $X$ which map an observation $x_i$ to a label $1$ through $K$, the minimum matching distance is defined as the minimum average number of mismatched labelings between the two clusterings, where the minimum is taken by permuting over the the clustering labels: \begin{align*}
mmd(C_1, C_2) = \frac{1}{n}\min_{\pi} \sum_{i=1}^n C_1(x_i) \neq \pi(C_2(x_i)).
\end{align*} While the minimization is done over a search-space of $K!$, seemingly rendering the metric infeasible for large values of $K$, mmd can be computed through the Hungarian algorithm in $O(K^3)$ time, which is utilized in the KMeansStability package throught calling the `RcppHungarian` library. To avoid the $O(K^3)$ time complexity, many have used comembership distance as a more computationally feasible alternative. The comembership distance between two pairs of clusterings $C_1$ and $C_2$ over a dataset $X$ is the average amount of pairs of observations which are within the same cluster in one clustering while split into different clusters in the other clustering: \begin{align*}
cd(C_1, C_2) = \frac{2}{n(n-1)}\sum_{i,j} I_{C_1(x_i) = C_1(x_j)}I_{C_2(x_i) \neq C_2(x_j)} + I_{C_1(x_i) \neq C_1(x_j)}I_{C_2(x_i) = C_2(x_j)}
\end{align*} Importantly, both of these metrics are defined over clusterings of *the same dataset*. In order to operationalize these metrics to compute the distance between clusterings developed on two distinct datasets, one is required to use a classifier to induce a set of labels on one dataset from the pair.

Motivated by this requirement, three additional stability metrics are implemented in this package to test their efficacy against mmd and cd. Utilizing the `transport` package (and embracing the subsequently long-runtimes), we consider three alternative metrics which can be evaluated on two distinct point-clouds:

1.  The Wasserstein distance between the two datasets where the observations within a given cluster are constrained to map to observations within one other cluster. This can be thought of as a minimum matching distance where the cost for each matching is the wasserstein distance between the point-clouds forming the two clusters being matched. This metric is denoted `wd`.

2.  The Wasserstein distance between the centroids defining the $K$-means clusterings where the centroids are given uniform mass. This metric is denoted `wd_cb`.

3.  The Wasserstein distance between the centroids where each centroid is given mass proportional to the amount of observations within the associated cluster.This metric is denoted `wd_cp`.

The above five metrics are jointly computed in the function `stability_analysis`, which jointly evaluates the distance metrics through either cross-validation or bootstrap resampling as the method for generating pairs of datasets.

```{r}
set.seed(3)
df <- toy_datagen() 

plot(df)
```

Above, we sample from a well-separated mixture model with three components. Below, we compute the average of the distance metrics taken over 4-fold cross-validation. In this case, the argument `nreps` specifies that the number of folds for the cross-validation is four; if bootstrapping were used instead, `nreps` would specify the number of bootstrap samples.

```{r}
results <- stability_analysis(df, 
                              Kmax = 6, 
                              method = "CV", 
                              nreps = 4)

results$mean_stabilities
```

We see that every metric attains its minima at the correct number of clusters.

Additionally, we can consider how these metrics perform on clustering a dataset generated by a data generating process with no clusters. Motivated by the Gap Statistic, `stability_analysis` also allows the used to compute the stability metrics of clusterings done over a uniform distribution oriented along the principle components of the input dataset. One might imagine that taking the difference between the mean stability metrics against the observed stability metrics could force a form of normalization on the metrics, regularizing them to avoid any natural upwards drift. Below shows a call to `stability_analysis` which computes the stability metrics over such a null sampling distribution, computing each metric via the same mechanism as the original sample. In this case, for each null sample, the sample is split into parts proportional to the folds used in the cross-validation of `df`.

```{r}
set.seed(3)
results <- stability_analysis(df, 
                              Kmax = 6, 
                              method = "CV",
                              nreps = 4, 
                              null_dist = T, 
                              nreps_null = 30)
results$mean_stabilities_gap

```

Above we see that the gap metrics all continue to select the correct number of clusters, with the largest value of the gap corresponding to the largest difference in stability in the observed dataset compared to the sample mean stability of the null datasets.
